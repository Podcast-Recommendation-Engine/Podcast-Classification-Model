{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cffeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# IMPORTS\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Deepchecks imports\n",
    "from deepchecks.tabular import Dataset, Suite\n",
    "from deepchecks.tabular.checks import (\n",
    "    # Data Integrity\n",
    "    IsSingleValue, MixedNulls, MixedDataTypes, StringMismatch,\n",
    "    DataDuplicates, ConflictingLabels, FeatureLabelCorrelation,\n",
    "    OutlierSampleDetection, SpecialCharacters,\n",
    "    \n",
    "    # Train-Test Validation\n",
    "    TrainTestLabelDrift, NewLabelTrainTest, TrainTestSamplesMix,\n",
    "    TrainTestFeatureDrift, CategoryMismatchTrainTest,\n",
    "    \n",
    "    # Model Performance\n",
    "    ConfusionMatrixReport, RocReport, SimpleModelComparison,\n",
    "    PerformanceReport, WeakSegmentsPerformance, ModelInferenceTime,\n",
    "    CalibrationScore, UnusedFeatures, BoostingOverfit\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" DEEPCHECKS COMPREHENSIVE VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\" Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ed5617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# CHARGEMENT DES DONNÉES\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" CHARGEMENT DES DONNÉES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df = pd.read_csv('../data/annotated/podcasts_annotated.csv')\n",
    "\n",
    "if 'keywords_text' not in df.columns:\n",
    "    df['keywords_text'] = df['keywords_clean'].apply(\n",
    "        lambda x: ' '.join(eval(x)) if isinstance(x, str) else ' '.join(x)\n",
    "    )\n",
    "\n",
    "X = df['keywords_text']\n",
    "y = df['is_kid_friendly']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\" Dataset: {len(df):,} exemples\")\n",
    "print(f\" Train: {len(X_train):,} ({len(X_train)/len(df)*100:.1f}%)\")\n",
    "print(f\" Test:  {len(X_test):,} ({len(X_test)/len(df)*100:.1f}%)\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61692fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# ENTRAÎNEMENT DU MODÈLE DE RÉFÉRENCE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" ENTRAÎNEMENT DU MODÈLE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Utiliser les meilleurs paramètres (à ajuster selon tuning)\n",
    "model = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(\n",
    "        max_features=None, min_df=2, max_df=0.95,\n",
    "        ngram_range=(1, 2), sublinear_tf=True\n",
    "    )),\n",
    "    ('clf', LogisticRegression(\n",
    "        C=1.0, max_iter=1000, random_state=42,\n",
    "        class_weight='balanced', solver='liblinear'\n",
    "    ))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "train_acc = accuracy_score(y_train, y_pred_train)\n",
    "test_acc = accuracy_score(y_test, y_pred_test)\n",
    "train_f1 = f1_score(y_train, y_pred_train)\n",
    "test_f1 = f1_score(y_test, y_pred_test)\n",
    "\n",
    "print(f\" ✓ Modèle entraîné: Logistic Regression\")\n",
    "print(f\"\\n Performances:\")\n",
    "print(f\"   • Train Accuracy: {train_acc:.4f}\")\n",
    "print(f\"   • Test Accuracy:  {test_acc:.4f}\")\n",
    "print(f\"   • Train F1-Score: {train_f1:.4f}\")\n",
    "print(f\"   • Test F1-Score:  {test_f1:.4f}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19258d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PRÉPARATION DES DATASETS DEEPCHECKS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PRÉPARATION DATASETS DEEPCHECKS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Créer DataFrames\n",
    "train_df = pd.DataFrame({\n",
    "    'keywords_text': X_train.values,\n",
    "    'is_kid_friendly': y_train.values\n",
    "})\n",
    "\n",
    "test_df = pd.DataFrame({\n",
    "    'keywords_text': X_test.values,\n",
    "    'is_kid_friendly': y_test.values\n",
    "})\n",
    "\n",
    "# Créer Deepchecks Datasets\n",
    "train_ds = Dataset(\n",
    "    train_df, \n",
    "    label='is_kid_friendly',\n",
    "    cat_features=[]\n",
    ")\n",
    "\n",
    "test_ds = Dataset(\n",
    "    test_df,\n",
    "    label='is_kid_friendly',\n",
    "    cat_features=[]\n",
    ")\n",
    "\n",
    "print(\" ✓ Datasets Deepchecks créés\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbcacc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PHASE 1: DATA INTEGRITY SUITE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PHASE 1: VALIDATION DE L'INTÉGRITÉ DES DONNÉES\")\n",
    "print(\"=\"*80)\n",
    "print(\" Vérifie la qualité et cohérence des données brutes\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "data_integrity_suite = Suite(\n",
    "    \"Data Integrity Validation\",\n",
    "    IsSingleValue(),                # Détecte features constantes\n",
    "    MixedNulls(),                   # Valeurs manquantes mixtes\n",
    "    MixedDataTypes(),               # Types incohérents\n",
    "    StringMismatch(),               # Problèmes d'encodage\n",
    "    DataDuplicates(),               # Duplicates exacts\n",
    "    ConflictingLabels(),            # Même input, labels différents\n",
    "    FeatureLabelCorrelation(),      # Corrélation feature-label\n",
    "    SpecialCharacters()             # Caractères spéciaux problématiques\n",
    ")\n",
    "\n",
    "data_integrity_result = data_integrity_suite.run(train_ds, test_ds)\n",
    "\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\" RÉSULTATS INTÉGRITÉ DES DONNÉES\")\n",
    "print(\"─\"*80)\n",
    "data_integrity_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa2a3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PHASE 2: TRAIN-TEST VALIDATION SUITE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PHASE 2: VALIDATION DU SPLIT TRAIN/TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\" Vérifie la qualité et cohérence du split\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "train_test_suite = Suite(\n",
    "    \"Train-Test Validation\",\n",
    "    TrainTestLabelDrift(),          # Drift distribution labels\n",
    "    NewLabelTrainTest(),            # Nouveaux labels dans test\n",
    "    TrainTestSamplesMix(),          # Data leakage\n",
    "    TrainTestFeatureDrift()         # Drift des features\n",
    ")\n",
    "\n",
    "train_test_result = train_test_suite.run(train_ds, test_ds)\n",
    "\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\" RÉSULTATS VALIDATION TRAIN/TEST\")\n",
    "print(\"─\"*80)\n",
    "train_test_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7034a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PHASE 3: MODEL PERFORMANCE SUITE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PHASE 3: VALIDATION DES PERFORMANCES DU MODÈLE\")\n",
    "print(\"=\"*80)\n",
    "print(\" Analyse approfondie des performances et erreurs\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "model_performance_suite = Suite(\n",
    "    \"Model Performance Validation\",\n",
    "    ConfusionMatrixReport(),        # Matrice de confusion détaillée\n",
    "    RocReport(),                    # Courbe ROC\n",
    "    SimpleModelComparison(),        # vs baseline simple\n",
    "    PerformanceReport(),            # Métriques complètes\n",
    "    WeakSegmentsPerformance(),      # Segments faibles\n",
    "    CalibrationScore()              # Calibration des probabilités\n",
    ")\n",
    "\n",
    "model_performance_result = model_performance_suite.run(train_ds, test_ds, model)\n",
    "\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\" RÉSULTATS PERFORMANCE MODÈLE\")\n",
    "print(\"─\"*80)\n",
    "model_performance_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2104ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# PHASE 4: ROBUSTNESS & PRODUCTION READINESS\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" PHASE 4: ROBUSTESSE ET PRODUCTION READINESS\")\n",
    "print(\"=\"*80)\n",
    "print(\" Vérifie la stabilité et performance du modèle\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "robustness_suite = Suite(\n",
    "    \"Robustness & Production Readiness\",\n",
    "    ModelInferenceTime(),           # Temps d'inférence\n",
    "    UnusedFeatures(),               # Features inutilisées\n",
    "    BoostingOverfit()               # Détection d'overfitting\n",
    ")\n",
    "\n",
    "robustness_result = robustness_suite.run(train_ds, test_ds, model)\n",
    "\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(\" RÉSULTATS ROBUSTESSE\")\n",
    "print(\"─\"*80)\n",
    "robustness_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b2f91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# RAPPORT DE SYNTHÈSE\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" RAPPORT DE SYNTHÈSE - VALIDATION COMPLÈTE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_suites = [\n",
    "    (\"Data Integrity\", data_integrity_result),\n",
    "    (\"Train-Test Validation\", train_test_result),\n",
    "    (\"Model Performance\", model_performance_result),\n",
    "    (\"Robustness\", robustness_result)\n",
    "]\n",
    "\n",
    "total_checks = 0\n",
    "total_passed = 0\n",
    "all_failed_checks = []\n",
    "\n",
    "for suite_name, result in all_suites:\n",
    "    suite_passed = 0\n",
    "    suite_total = 0\n",
    "    \n",
    "    for check_result in result.results:\n",
    "        suite_total += 1\n",
    "        if check_result.passed():\n",
    "            suite_passed += 1\n",
    "        else:\n",
    "            all_failed_checks.append({\n",
    "                'suite': suite_name,\n",
    "                'check': check_result.get_header(),\n",
    "                'severity': 'HIGH' if hasattr(check_result, 'priority') and check_result.priority > 2 else 'MEDIUM'\n",
    "            })\n",
    "    \n",
    "    total_checks += suite_total\n",
    "    total_passed += suite_passed\n",
    "    \n",
    "    status = \"✓\" if suite_passed == suite_total else \"⚠\"\n",
    "    print(f\"\\n{status} {suite_name}:\")\n",
    "    print(f\"   Checks réussis: {suite_passed}/{suite_total} ({suite_passed/suite_total*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"─\"*80)\n",
    "print(f\" TOTAL: {total_passed}/{total_checks} checks réussis ({total_passed/total_checks*100:.1f}%)\")\n",
    "print(\"─\"*80)\n",
    "\n",
    "if all_failed_checks:\n",
    "    print(f\"\\n⚠ {len(all_failed_checks)} checks échoués:\")\n",
    "    for failed in all_failed_checks:\n",
    "        print(f\"   [{failed['severity']}] {failed['suite']}: {failed['check']}\")\n",
    "    print(\"\\n→ Recommandations:\")\n",
    "    print(\"   1. Examiner les résultats détaillés ci-dessus\")\n",
    "    print(\"   2. Corriger les problèmes HIGH priority\")\n",
    "    print(\"   3. Évaluer l'impact des problèmes MEDIUM\")\n",
    "else:\n",
    "    print(\"\\n✓ TOUS LES CHECKS SONT PASSÉS!\")\n",
    "    print(\"   → Modèle validé et prêt pour la production\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\" Validation terminée: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d112bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# EXPORT DES RAPPORTS HTML\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" EXPORT DES RAPPORTS HTML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Créer le dossier reports s'il n'existe pas\n",
    "reports_dir = '../models/validation_reports'\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "try:\n",
    "    # Export de chaque suite\n",
    "    data_integrity_result.save_as_html(\n",
    "        f'{reports_dir}/01_data_integrity_{timestamp}.html'\n",
    "    )\n",
    "    print(f\" ✓ Data Integrity: 01_data_integrity_{timestamp}.html\")\n",
    "    \n",
    "    train_test_result.save_as_html(\n",
    "        f'{reports_dir}/02_train_test_validation_{timestamp}.html'\n",
    "    )\n",
    "    print(f\" ✓ Train-Test: 02_train_test_validation_{timestamp}.html\")\n",
    "    \n",
    "    model_performance_result.save_as_html(\n",
    "        f'{reports_dir}/03_model_performance_{timestamp}.html'\n",
    "    )\n",
    "    print(f\" ✓ Model Performance: 03_model_performance_{timestamp}.html\")\n",
    "    \n",
    "    robustness_result.save_as_html(\n",
    "        f'{reports_dir}/04_robustness_{timestamp}.html'\n",
    "    )\n",
    "    print(f\" ✓ Robustness: 04_robustness_{timestamp}.html\")\n",
    "    \n",
    "    print(f\"\\n → Tous les rapports sauvegardés dans: {reports_dir}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\" ⚠ Erreur d'export: {str(e)}\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================\n",
    "# DÉCISION FINALE: PRODUCTION READY?\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" DÉCISION FINALE: PRODUCTION READINESS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Critères de décision\n",
    "min_pass_rate = 0.85  # 85% des checks doivent passer\n",
    "pass_rate = total_passed / total_checks\n",
    "\n",
    "# Checks critiques qui doivent absolument passer\n",
    "critical_checks = [\n",
    "    'TrainTestSamplesMix',      # Data leakage\n",
    "    'ConflictingLabels',        # Labels conflictuels\n",
    "    'SimpleModelComparison'     # Meilleur que baseline\n",
    "]\n",
    "\n",
    "critical_passed = True\n",
    "for check in all_failed_checks:\n",
    "    check_name = check['check']\n",
    "    if any(critical in check_name for critical in critical_checks):\n",
    "        critical_passed = False\n",
    "        print(f\" ✗ CHECK CRITIQUE ÉCHOUÉ: {check['check']}\")\n",
    "\n",
    "print(f\"\\nTaux de réussite: {pass_rate*100:.1f}% (minimum requis: {min_pass_rate*100:.0f}%)\")\n",
    "print(f\"Checks critiques: {'✓ PASSÉS' if critical_passed else '✗ ÉCHOUÉS'}\")\n",
    "\n",
    "if pass_rate >= min_pass_rate and critical_passed:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" ✓✓✓ MODÈLE VALIDÉ POUR LA PRODUCTION ✓✓✓\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n Prochaines étapes:\")\n",
    "    print(\"   1. Exécuter 07_model_registry.ipynb pour enregistrer le modèle\")\n",
    "    print(\"   2. Configurer le monitoring en production\")\n",
    "    print(\"   3. Mettre en place le pipeline de réentraînement\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\" ⚠⚠⚠ MODÈLE NON VALIDÉ POUR LA PRODUCTION ⚠⚠⚠\")\n",
    "    print(\"=\"*80)\n",
    "    print(\"\\n Actions requises:\")\n",
    "    print(\"   1. Corriger les checks échoués (voir détails ci-dessus)\")\n",
    "    print(\"   2. Réentraîner le modèle si nécessaire\")\n",
    "    print(\"   3. Relancer cette validation\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\" FIN DE LA VALIDATION COMPLÈTE\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
